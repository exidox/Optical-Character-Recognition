{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images\\word.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "thresh = cv2.threshold(blur, 100,255 ,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 1600, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' cv2.imshow(\"thresh\", thresh)\\ncv2.waitKey(0) '"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" cv2.imshow(\"thresh\", thresh)\n",
    "cv2.waitKey(0) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' cv2.imshow(\"ker\", kernel)\\ncv2.waitKey(0) '"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" cv2.imshow(\"ker\", kernel)\n",
    "cv2.waitKey(0) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilate = cv2.dilate(thresh, kernel , iterations = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' cv2.imshow(\"di\", dilate)\\ncv2.waitKey(0) '"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" cv2.imshow(\"di\", dilate)\n",
    "cv2.waitKey(0) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts =cnts[0] if len(cnts) == 2 else cnts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = sorted(cnts, key = lambda x : cv2.boundingRect(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list= []\n",
    "for i in range(97, 123):\n",
    "    label_list.append(chr(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(\"OCR_MODEL.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 28, 28)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "highest accuracy 0.7781556\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 28, 28)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "highest accuracy 0.9997222\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 28, 28)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "highest accuracy 0.9999739\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 28, 28)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "highest accuracy 0.93591595\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 28, 28)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "highest accuracy 0.99171925\n"
     ]
    }
   ],
   "source": [
    "ans =\"\"\n",
    "\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    if h>50 and w >20 :\n",
    "        roi = image[y:y+h+20, x:x+h+20]\n",
    "        cv2.imshow(\"roi\", roi)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), (36,255,12), 2)\n",
    "\n",
    "        img=cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        _, img = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        img = cv2.bitwise_not(img)\n",
    "\n",
    "        img = cv2.resize(img, (28, 28))\n",
    "        x = asarray(img)\n",
    "        x = x.astype('float32')/255.0\n",
    "\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        x = np.where(x=='True', 1, x)\n",
    "        x = np.where(x=='False', 0, x)\n",
    "        \n",
    "        print(type(x))\n",
    "        print(x.shape)\n",
    "\n",
    "        ocr_result = model.predict(x)\n",
    "\n",
    "        print(\"highest accuracy \" + str(ocr_result.max()))\n",
    "        max = ocr_result.max()\n",
    "        index = ocr_result.argmax()\n",
    "\n",
    "        ans = ans + str((label_list[index]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
